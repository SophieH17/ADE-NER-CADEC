{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdMuL-KJzNAw"
      },
      "source": [
        "# Load Data & Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "d5dae25ce3c34cc686d9132198fddf1b"
          ]
        },
        "id": "HkONdCupzNA-",
        "outputId": "d0c66022-1ca6-4460-ef80-eca4d93ee985"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFNOzz-gzNA0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from transformers import AutoTokenizer\n",
        "from datasets import Dataset\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nT_DJ1Ux2XW1"
      },
      "outputs": [],
      "source": [
        "model_checkpoint = \"bert-base-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kWMwZbi2YRl"
      },
      "outputs": [],
      "source": [
        "model_checkpoint = \"albert-base-v2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CroIY3mgzNA2"
      },
      "outputs": [],
      "source": [
        "def load_data(text_dir, ann_dir, num_files=None):\n",
        "    data = []\n",
        "    text_files = sorted(os.listdir(text_dir))[:num_files]\n",
        "    ann_files = sorted(os.listdir(ann_dir))[:num_files]\n",
        "\n",
        "    for txt_file, ann_file in zip(text_files, ann_files):\n",
        "        with open(os.path.join(text_dir, txt_file), 'r') as f:\n",
        "            lines = f.read().split('\\n')\n",
        "\n",
        "        line_labels = [{} for _ in lines]  \n",
        "\n",
        "        with open(os.path.join(ann_dir, ann_file), 'r') as f:\n",
        "            for line in f:\n",
        "                if line.startswith('T'):\n",
        "                    parts = line.split('\\t')\n",
        "                    label_type_and_positions = parts[1].split(' ')\n",
        "                    label_type = label_type_and_positions[0]\n",
        "                    positions = ' '.join(label_type_and_positions[1:]).split(';')\n",
        "                    for position in positions:\n",
        "                        position_parts = position.strip().split(' ')\n",
        "                        for i in range(0, len(position_parts), 2):\n",
        "                            start, end = map(int, position_parts[i:i+2])\n",
        "                            for line_index, line in enumerate(lines):\n",
        "                                line_start = sum(len(l) + 1 for l in lines[:line_index]) \n",
        "                                line_end = line_start + len(line)\n",
        "                                if line_start <= start < line_end and line_start < end <= line_end:\n",
        "                                    if label_type not in line_labels[line_index]:\n",
        "                                        line_labels[line_index][label_type] = []\n",
        "                                    line_labels[line_index][label_type].append((start - line_start, end - line_start))\n",
        "\n",
        "        for line_index, line in enumerate(lines):\n",
        "            if line:\n",
        "                data.append({\n",
        "                    'id': f'{txt_file.split(\".\")[0]}_{line_index}',\n",
        "                    'text': line,\n",
        "                    'labels': line_labels[line_index],\n",
        "                    'file_names': txt_file\n",
        "                })\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    dataset = Dataset.from_pandas(df)\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrnbzAdAzNA3",
        "outputId": "a62fd9c9-ac30-4982-a5fd-9d023da24bf9"
      },
      "outputs": [],
      "source": [
        "text_dir = \"cadec\\\\text\"\n",
        "ann_dir = \"cadec\\\\original\"\n",
        "\n",
        "dataset = load_data(text_dir, ann_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHl8Djy0zNA3"
      },
      "outputs": [],
      "source": [
        "label_names = ['O', 'B-Drug', 'I-Drug', 'B-ADR', 'I-ADR', 'B-Disease', 'I-Disease', 'B-Symptom', 'I-Symptom','B-Finding', 'I-Finding']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOMEkp2QzNA4"
      },
      "outputs": [],
      "source": [
        "from datasets import ClassLabel, Sequence\n",
        "\n",
        "ner_feature = Sequence(feature=ClassLabel(num_classes=11,\n",
        "                                          names=['O', 'B-Drug', 'I-Drug', 'B-ADR', 'I-ADR', 'B-Disease', 'I-Disease', 'B-Symptom', 'I-Symptom','B-Finding', 'I-Finding']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "cfaf9655a4f04a838e3fb57a8ca55b98"
          ]
        },
        "id": "38A1ZzBrzNA4",
        "outputId": "7007a4d9-6a9e-4f43-df45-e3a90676004c"
      },
      "outputs": [],
      "source": [
        "def encode_example(example):\n",
        "    encoding = tokenizer(example['text'], truncation=True, padding=True, max_length=512)\n",
        "    tokens = tokenizer.convert_ids_to_tokens(encoding['input_ids'])\n",
        "\n",
        "    labels = ['O'] * len(encoding['input_ids'])\n",
        "\n",
        "    for label_type, positions in example['labels'].items():\n",
        "        if positions is not None:\n",
        "            for start, end in positions:\n",
        "                # Convert character positions to token positions\n",
        "                start_token, end_token = encoding.char_to_token(start), encoding.char_to_token(end - 1)\n",
        "                if start_token is not None and end_token is not None:\n",
        "                    labels[start_token] = 'B-' + label_type\n",
        "                    for i in range(start_token + 1, end_token + 1):\n",
        "                        labels[i] = 'I-' + label_type\n",
        "\n",
        "    labels = [ner_feature.feature.str2int(label) for label in labels]\n",
        "\n",
        "    labels[0] = labels[-1] = -100\n",
        "    labels = [label if token not in ['[CLS]', '[SEP]', '[PAD]'] else -100 for token, label in zip(tokens, labels)]\n",
        "\n",
        "    return {'input_ids': encoding['input_ids'], 'attention_mask': encoding['attention_mask'], 'tokens': tokens, 'labels': labels}\n",
        "\n",
        "dataset = dataset.map(encode_example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlYwWf9bzNA5",
        "outputId": "1b345ab1-d1a7-42e6-fb90-e4754f5c8b75"
      },
      "outputs": [],
      "source": [
        "i=145\n",
        "print(dataset[i]['file_names'])\n",
        "tokens = dataset[i]['tokens']\n",
        "tags = dataset[i]['labels']\n",
        "\n",
        "for token, tag in zip(tokens, tags):\n",
        "    if tag != -100:\n",
        "        tag = label_names[tag]\n",
        "    print(f\"Token: {token}, Tag: {tag}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6bGrgaxzNA5"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRYwK3uizNA6",
        "outputId": "182d2d8f-b531-402c-d61e-8204626c5e9a"
      },
      "outputs": [],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "108a25df3d3f4d22a72a230377fbb8fd",
            "96d2fc5b820a4506a5beaf45dc8c2edd",
            "afd27ee401164e978c8621669b5c2137"
          ]
        },
        "id": "BxlyQdWdzNA6",
        "outputId": "b088f79c-4866-4b71-9b12-d92089bc6ee3"
      },
      "outputs": [],
      "source": [
        "from datasets import DatasetDict\n",
        "\n",
        "dataset = dataset.train_test_split(test_size=0.2, seed=1)\n",
        "train_validation_dataset = dataset['train'].train_test_split(test_size=0.1, seed=1)\n",
        "\n",
        "dataset = DatasetDict({\n",
        "    'train': train_validation_dataset['train'],\n",
        "    'validation': train_validation_dataset['test'],\n",
        "    'test': dataset['test']\n",
        "})\n",
        "\n",
        "def select_fields(example):\n",
        "    return {'input_ids': example['input_ids'], 'labels': example['labels'], 'attention_mask': example['attention_mask']}\n",
        "\n",
        "processed_dataset = dataset.map(select_fields,remove_columns=['tokens', 'file_names','id','text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9k51dj2szNA6",
        "outputId": "a1f6a011-1b84-43d3-f392-ce9f0fb62bee"
      },
      "outputs": [],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVe4rmENzNA7",
        "outputId": "f8271346-0d0a-432b-9db3-a93184a17bb5"
      },
      "outputs": [],
      "source": [
        "processed_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ByvXxZkzNA7"
      },
      "source": [
        "# Explore the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lPKAEQQzNA7",
        "outputId": "da553567-8bd3-4897-bfec-cc7dfbc76165"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "\n",
        "labels = ['ADR', 'Drug', 'Disease', 'Symptom', 'Finding']\n",
        "\n",
        "co_occurrence_matrix = np.zeros((len(labels), len(labels)))\n",
        "\n",
        "for filename in os.listdir('cadec/original'):\n",
        "    if filename.endswith('.ann'):\n",
        "        with open(os.path.join('cadec/original', filename), 'r') as file:\n",
        "\n",
        "            label_dict = defaultdict(int)\n",
        "            for line in file:\n",
        "                label = line.split('\\t')[1].split()[0]\n",
        "                if label in labels:\n",
        "                    label_dict[label] += 1\n",
        "\n",
        "            for i in range(len(labels)):\n",
        "                for j in range(i, len(labels)):\n",
        "                    if label_dict[labels[i]] > 0 and label_dict[labels[j]] > 0:\n",
        "                        co_occurrence_matrix[i, j] += 1\n",
        "                        if i != j:\n",
        "                            co_occurrence_matrix[j, i] += 1\n",
        "plt.figure(figsize=(7, 7))\n",
        "plt.imshow(co_occurrence_matrix, cmap='hot', interpolation='nearest')\n",
        "plt.colorbar(label='co-occurrence frequency', orientation='horizontal')\n",
        "\n",
        "plt.xticks(np.arange(len(labels)), labels, rotation=0)\n",
        "plt.yticks(np.arange(len(labels)), labels)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMNUqYH2zNA7",
        "outputId": "38a71cba-bfeb-461f-8fbf-88ad2c4a255e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from collections import defaultdict\n",
        "\n",
        "labels = ['ADR', 'Drug', 'Disease', 'Symptom', 'Finding']\n",
        "label_counts = defaultdict(int)\n",
        "for filename in os.listdir('cadec/original'):\n",
        "    if filename.endswith('.ann'):\n",
        "        with open(os.path.join('cadec/original', filename), 'r') as file:\n",
        "            for line in file:\n",
        "                if line.startswith('T'):\n",
        "                    label = line.split('\\t')[1].split()[0]\n",
        "                    if label in labels:\n",
        "                        label_counts[label] += 1\n",
        "\n",
        "for label, count in label_counts.items():\n",
        "    print(f'{label}: {count}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ErytwJUzNA8",
        "outputId": "2cf59eb8-922b-4e3d-a6d9-3f8fdfb05774"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "labels = []\n",
        "\n",
        "for split in ['train', 'validation', 'test']:\n",
        "    for example in dataset[split]:\n",
        "        for tag in example['labels']:\n",
        "            if tag != -100:\n",
        "                labels.append(tag)\n",
        "label_counts = Counter(labels)\n",
        "\n",
        "total_freqs = {label_names[label]: count for label, count in label_counts.items()}\n",
        "total_ratio = {label: round(freq / sum(total_freqs.values()), 3) for label, freq in total_freqs.items()} \n",
        "for label in total_freqs.keys():\n",
        "    print(f\"Label: {label}, Frequency: {total_freqs[label]}, Ratio: {total_ratio[label]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIG_d1uzzNA8",
        "outputId": "2299c500-f135-4fe6-e37c-ad67709c32ea"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "\n",
        "label_counts = {'train': defaultdict(int), 'validation': defaultdict(int), 'test': defaultdict(int)}\n",
        "for split in ['train', 'validation', 'test']:\n",
        "    for example in dataset[split]:\n",
        "        for tag in example['labels']:\n",
        "            if tag != -100:  \n",
        "                label = label_names[tag]\n",
        "                label_counts[split][label] += 1\n",
        "fig, ax = plt.subplots(figsize=(12, 6))  \n",
        "width = 0.2\n",
        "x = range(len(label_names))\n",
        "for i, split in enumerate(['train', 'validation', 'test']):\n",
        "    counts = [label_counts[split][label] for label in label_names]\n",
        "    ax.bar([xi + i * width for xi in x], counts, width, label=split)\n",
        "\n",
        "ax.set_ylabel('Counts (log scale)')\n",
        "ax.set_yscale('log')  \n",
        "ax.set_title('Label distribution in each split')\n",
        "ax.set_xticks([xi + width for xi in x])\n",
        "ax.set_xticklabels(label_names)\n",
        "ax.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fz6E_eSKzNA8"
      },
      "source": [
        "# Define Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpNGDM-MzNA9",
        "outputId": "d2a4bfe7-88e2-4593-fd77-ea26985a7830"
      },
      "outputs": [],
      "source": [
        "for split in ['train', 'validation', 'test']:\n",
        "    sample = dataset[split][140]\n",
        "    tokens = sample['tokens']\n",
        "    labels = sample['labels']\n",
        "    labels = [label_names[label] if label != -100 else '-100' for label in labels]\n",
        "    print(f'Split: {split}')\n",
        "    print(sample['file_names'])\n",
        "    for token, label in zip(tokens, labels):\n",
        "        print(f'Token: {token:<15} Label: {label}')\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXQn-wFlzNA9"
      },
      "outputs": [],
      "source": [
        "id2label = {str(i): label for i, label in enumerate(label_names)}\n",
        "label2id = {v: k for k, v in id2label.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dc_zOuV_zNA9",
        "outputId": "df050f32-2e78-4958-afad-c97f8c093607"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForTokenClassification\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0b8sn_4yzNA9"
      },
      "outputs": [],
      "source": [
        "# Metrics\n",
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"seqeval\")\n",
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
        "    true_predictions = [\n",
        "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    return all_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97DTs663zNA9",
        "outputId": "247d16f3-3c84-474c-9169-15f3ccf4227e"
      },
      "outputs": [],
      "source": [
        "model.config.num_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WACInolNzNA-"
      },
      "source": [
        "# BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aC4qM9ZT25De"
      },
      "source": [
        "## Hyper-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTgIlhHF3MM-"
      },
      "source": [
        "### Baseline Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tns66hgazNA-"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"cadec_baseline\", \n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    push_to_hub=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "0621f9efc0c94a7cb4842823a356e696",
            "9b26c997d080491e9e62fb16f7c3de07",
            "b7096489caad4941bf79d3c27089267b",
            "857cc711605c4cb1abd5d1cb1b2cbefa"
          ]
        },
        "id": "xBiv3hNrzNA-",
        "outputId": "29613725-070b-4282-a08d-73e7abed423f"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer_0 = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=processed_dataset[\"train\"],\n",
        "    eval_dataset=processed_dataset[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "trainer_0.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "ad9a3df88d124a1caafdc3f30a49e90b"
          ]
        },
        "id": "8fwBBjfQzNA-",
        "outputId": "9294c982-d431-4158-9d6e-81a5489d6b6b"
      },
      "outputs": [],
      "source": [
        "predictions, labels, _ = trainer_0.predict(processed_dataset[\"validation\"])\n",
        "\n",
        "predicted_indices = np.argmax(predictions, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8wWEyKRzNA-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_preds_and_labels(eval_preds):\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
        "    true_predictions = [\n",
        "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    return true_labels, true_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQdn8KTzzNA_",
        "outputId": "444d77f3-941f-4d53-a510-855a7c8264af"
      },
      "outputs": [],
      "source": [
        "true_labels,true_predictions = get_preds_and_labels((predictions, labels))\n",
        "print(true_labels[0])\n",
        "print(true_predictions[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVlg35UkzNA_"
      },
      "outputs": [],
      "source": [
        "all_metrics = metric.compute(predictions=true_predictions, references=true_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nB7yfOK1zNA_",
        "outputId": "5168ed71-ff7d-45a8-9d31-522fa8919c6d"
      },
      "outputs": [],
      "source": [
        "all_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHz6hpXkzNA_"
      },
      "source": [
        "### Other Combinations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIjvp2eEzNA_"
      },
      "outputs": [],
      "source": [
        "def compute_metrics_tune(eval_preds):\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
        "    true_predictions = [\n",
        "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": all_metrics[\"overall_precision\"],\n",
        "        \"recall\": all_metrics[\"overall_recall\"],\n",
        "        \"f1\": all_metrics[\"overall_f1\"],\n",
        "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRSL_0g0zNA_"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "def optuna_hp_space(trial):\n",
        "    return {\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-6, 1e-4, log=True),\n",
        "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [16, 32, 64]),\n",
        "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.0, 0.3),\n",
        "        \"warmup_steps\": trial.suggest_int(\"warmup_steps\", 0, 500),\n",
        "        \"gradient_accumulation_steps\": trial.suggest_int(\"gradient_accumulation_steps\", 1, 10),\n",
        "    }\n",
        "\n",
        "def model_init(trial):\n",
        "    return AutoModelForTokenClassification.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ")\n",
        "\n",
        "args_tuner = TrainingArguments(\n",
        "    output_dir='./results',         \n",
        "    evaluation_strategy=\"epoch\",\n",
        "    optim=\"adamw_torch\",\n",
        "    num_train_epochs=0.3,             \n",
        "    per_device_train_batch_size=16, \n",
        "    per_device_eval_batch_size=64,  \n",
        "    warmup_steps=500,               \n",
        "    weight_decay=0.01,              \n",
        "    logging_dir='./logs',          \n",
        "    logging_steps=10,\n",
        "    gradient_accumulation_steps=1,  \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUmhWsVzzNBE",
        "outputId": "50297953-a8e6-4c44-8036-d21f9e5f62c5"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "trainer_tuner = Trainer(\n",
        "    model=None,\n",
        "    args=args_tuner,\n",
        "    train_dataset=processed_dataset[\"train\"],\n",
        "    eval_dataset=processed_dataset[\"validation\"],\n",
        "    compute_metrics=compute_metrics_tune,\n",
        "    tokenizer=tokenizer,\n",
        "    model_init=model_init,\n",
        "    data_collator=data_collator,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "ab41d13de1624ac5b0f10581edcd3675",
            "fe43013bcd614f99932c0a153811ff12",
            "f251e575f13c46d3a5d7ea87f9576457",
            "81ada63118ae4163aa37a82bef2d8b1f",
            "d67ba986c62a45c394663e945f6ce5d6",
            "5d50ef54aaa44e909ea7d48b66573c91",
            "2348606a5f014356bca96d014e9b082b",
            "7c0935e290a34960a396857dca26c2ea",
            "1ae662c5d6c44e90bbc178d0a307d5bd",
            "ee60bca1e4a043bda3ec4887fd1c5efa",
            "9d86e35a5aee48128b489836035bf4ad",
            "776b96670e63459b9f35d5e1eb1fd0f8",
            "cf9101c8e2e24a82bc43f4756f0834fb",
            "69bb55b2a3c047f7afff2984c24c16dc",
            "9de16b51f6b94812921fac7ec9bbf02c",
            "1932703088c24f8094ab4d3e6b70b44e",
            "c43f560e52ee404381d95120a9ba5837",
            "b65252d876784e00ad3bd58933454301",
            "ce158303ff3547f8bda0b2486814d485",
            "6eb4b288180e46e6ad404c2158ebf733",
            "1ed4833e78354590a0d59585140f08d9",
            "5089db00a79f42dba91d3ff14439cc33",
            "07fc6f3f1832468aa778103ad02c3535",
            "20da990c01964f35938bbf09d0bd8ffa",
            "a38f219c314f4897baa3e1364b5efd03",
            "e89891e07c674eeda38da2c253024004",
            "9fad48cf864d409eacbbdf444da4fae8",
            "de753340368446058d56dc82b029f721",
            "7aef336c10c7444fa0f313c6c905b138",
            "34d9b88bae044ab69744078829d148b2",
            "8c9651310046404d8d61bc9605374587",
            "762d0612a4c84484862012e80300a247",
            "7ffd6650416740588562b8c1ea002363",
            "eaee9cc5cf5446279ebc1b1679c2e6c8",
            "c75030c5106f44e0bbd911b163004d5c",
            "68539739903f40509609c8eafcef718c",
            "fd10b4b2b9d24e8c9e8f7a82106ea258",
            "92359f1f22184eb2a58aa1a4947687fa",
            "24dc0516e6664a1a87146a164db482f7",
            "ebacaac5a779491cb719a6057b46e111"
          ]
        },
        "id": "wqiLRuQ6zNBE",
        "outputId": "60945548-4491-4e06-c40f-3dc5c7352de7"
      },
      "outputs": [],
      "source": [
        "best_trial = trainer_tuner.hyperparameter_search(\n",
        "    direction=\"maximize\",\n",
        "    backend=\"optuna\",\n",
        "    hp_space=optuna_hp_space,\n",
        "    n_trials=20\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enKeTQbWzNBF",
        "outputId": "5ba44050-f996-483b-a9da-60d4ac78c289"
      },
      "outputs": [],
      "source": [
        "print(f\"Best Trial Score: {best_trial.objective}\")\n",
        "print(f\"Best Hyperparameters: {best_trial.hyperparameters}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5YlN0ohzNBF"
      },
      "source": [
        "#### Model 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQRucTpezNBF",
        "outputId": "f206430a-d254-43c5-f49c-ee24516869de"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gxT4lZbzNBF"
      },
      "outputs": [],
      "source": [
        "args_test = []\n",
        "args_test.append(TrainingArguments(\n",
        "    output_dir=\"./results\", \n",
        "    optim=\"adamw_torch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=32,  \n",
        "    per_device_eval_batch_size=64,   \n",
        "    learning_rate=5.97795988468052e-05,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.29365893220385486,\n",
        "    warmup_steps=176,\n",
        "    gradient_accumulation_steps=6,\n",
        "    logging_dir='./logs',      \n",
        "    logging_steps=10,\n",
        "    push_to_hub=False,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=100, \n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "48e3171694104ca99ecd0a7ec881e94b"
          ]
        },
        "id": "gk7b2xPlzNBF",
        "outputId": "bbadd2f7-7b05-476a-f7fc-61c2e1759668"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "trainer_test = []\n",
        "trainer_test.append(Trainer(\n",
        "    model=model,\n",
        "    args=args_test[0],\n",
        "    train_dataset=processed_dataset[\"train\"],\n",
        "    eval_dataset=processed_dataset[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics_tune,\n",
        "    tokenizer=tokenizer,\n",
        "))\n",
        "trainer_test[0].train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UB36sKyjzNBG",
        "outputId": "7f605dc8-5368-469f-d1dd-f7507c32a715"
      },
      "outputs": [],
      "source": [
        "trainer_test[0].state.log_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "3d0e09c48121414992c5f4c73d74d1bc"
          ]
        },
        "id": "uXSBbxeNzNBG",
        "outputId": "0ec3a24e-dd5e-412e-9477-921f1b532060"
      },
      "outputs": [],
      "source": [
        "predictions, labels, _ = trainer_test[0].predict(processed_dataset[\"validation\"])\n",
        "predicted_indices = np.argmax(predictions, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hi2jmAouzNBG"
      },
      "outputs": [],
      "source": [
        "true_labels,true_predictions = get_preds_and_labels((predictions, labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxRIhPhozNBG",
        "outputId": "22cbad34-dc56-40ef-f29d-d4977806f930"
      },
      "outputs": [],
      "source": [
        "all_metrics = []\n",
        "all_metrics.append(metric.compute(predictions=true_predictions, references=true_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVhqNECszNBG",
        "outputId": "5ec4849e-4fba-4428-e360-e959430bd61d"
      },
      "outputs": [],
      "source": [
        "all_metrics[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBJG2TT2zNBG"
      },
      "source": [
        "#### Model 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MjKcXdZzNBH"
      },
      "outputs": [],
      "source": [
        "args_test.append(TrainingArguments(\n",
        "    output_dir=\"./results\", \n",
        "    optim=\"adamw_torch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=16, \n",
        "    per_device_eval_batch_size=64,   \n",
        "    learning_rate=5.753308827948429e-05,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.2990812548264342,\n",
        "    warmup_steps=213,\n",
        "    gradient_accumulation_steps=8,\n",
        "    logging_dir='./logs',        \n",
        "    logging_steps=10,\n",
        "    push_to_hub=False,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "6d8efac948f74c4ebb4527124495c3a4",
            "0ddd01c140d14759891cce85afadd588",
            "22ac5d7e48384b509f919c72a299b76e",
            "a040428ce8a047a3ad5d805d3bea619d"
          ]
        },
        "id": "33RsIUSUzNBH",
        "outputId": "80e028f0-2412-4f80-df6d-5c1756935fa4"
      },
      "outputs": [],
      "source": [
        "trainer_test.append(Trainer(\n",
        "    model=model,\n",
        "    args=args_test[1],\n",
        "    train_dataset=processed_dataset[\"train\"],\n",
        "    eval_dataset=processed_dataset[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics_tune,\n",
        "    tokenizer=tokenizer,\n",
        "))\n",
        "trainer_test[1].train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "77a7b57ed9d14718b5a760c9e651f323"
          ]
        },
        "id": "6QlVJp2GzNBH",
        "outputId": "b8e758c3-ad76-4027-ee07-29f0e4577fbe"
      },
      "outputs": [],
      "source": [
        "predictions, labels, _ = trainer_test[1].predict(processed_dataset[\"validation\"])\n",
        "predicted_indices = np.argmax(predictions, axis=-1)\n",
        "true_labels,true_predictions = get_preds_and_labels((predictions, labels))\n",
        "all_metrics.append(metric.compute(predictions=true_predictions, references=true_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8S44ZAVzNBH",
        "outputId": "f5be91b0-a3a3-4af7-fb3d-d7b97b406a19"
      },
      "outputs": [],
      "source": [
        "all_metrics[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPqgBuaLzNBI"
      },
      "source": [
        "#### Model 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYStGrAIzNBI"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "from transformers import Trainer\n",
        "args_test = TrainingArguments(\n",
        "    output_dir=\"./results\", \n",
        "    optim=\"adamw_torch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=32, \n",
        "    per_device_eval_batch_size=64,  \n",
        "    learning_rate=9.367839518177488e-05,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.26268932261420513,\n",
        "    warmup_steps=61,\n",
        "    gradient_accumulation_steps=7,\n",
        "    logging_dir='./logs',         \n",
        "    logging_steps=10,\n",
        "    push_to_hub=False,\n",
        "    evaluation_strategy=\"epoch\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "45ac9f4c3760441a86dae912c9a42a82",
            "8dbfc02d72704f77ab761591570e643b",
            "ef02cfd7787d4d4fa2a2bc7d582ba127",
            "214045dfb78e4fcdb928fcf586bba1d6"
          ]
        },
        "id": "9JQDm_EizNBI",
        "outputId": "1ba8de9b-a333-4a75-dc65-dbe332f34c2d"
      },
      "outputs": [],
      "source": [
        "trainer_test = Trainer(\n",
        "    model=model,\n",
        "    args=args_test,\n",
        "    train_dataset=processed_dataset[\"train\"],\n",
        "    eval_dataset=processed_dataset[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics_tune,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "trainer_test.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "587808df26f04f04b153b1fe6e0753e4"
          ]
        },
        "id": "qp9nUPPezNBI",
        "outputId": "89a3cad2-9278-4852-f2ff-cd7108d6af3f"
      },
      "outputs": [],
      "source": [
        "predictions, labels, _ = trainer_test.predict(processed_dataset[\"validation\"])\n",
        "predicted_indices = np.argmax(predictions, axis=-1)\n",
        "true_labels,true_predictions = get_preds_and_labels((predictions, labels))\n",
        "all_metrics=metric.compute(predictions=true_predictions, references=true_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftvltH3rzNBI",
        "outputId": "97edfa86-4eb1-4ba5-f2bc-fba773418403"
      },
      "outputs": [],
      "source": [
        "all_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4o35PRCzNBJ"
      },
      "source": [
        "## Complete Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUPYQHEyzNBJ"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"cadec_baseline\", \n",
        "    logging_dir='./logs',\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    push_to_hub=True,\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=100, \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "39634cd5c01d45aeb467b532a0505501",
            "189bb36bb45e4418a36d12b486d867f1",
            "bf4e69a69a464db18345d74d79d4c563",
            "67931df31313416db836e2684503fbad"
          ]
        },
        "id": "MJZG9wnjzNBJ",
        "outputId": "d3e262a9-eec3-4d8f-e018-2f86ec6485b6"
      },
      "outputs": [],
      "source": [
        "from datasets import concatenate_datasets\n",
        "\n",
        "train_val_dataset = concatenate_datasets([processed_dataset[\"train\"], processed_dataset[\"validation\"]])\n",
        "\n",
        "trainer_1 = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_val_dataset,  \n",
        "    eval_dataset=processed_dataset[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics_tune,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "trainer_1.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsuktwyezNBJ",
        "outputId": "3bc1c503-e167-4189-ce6c-63ca87bf1897"
      },
      "outputs": [],
      "source": [
        "trainer_1.state.log_history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nIyZ3V3zNBK"
      },
      "source": [
        "### Reports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yO6n277HzNBK"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForTokenClassification\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    'cadec_baseline/checkpoint-2280',\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5qh-npTzNBK"
      },
      "outputs": [],
      "source": [
        "from datasets import concatenate_datasets\n",
        "from transformers import Trainer\n",
        "\n",
        "train_val_dataset = concatenate_datasets([processed_dataset[\"train\"], processed_dataset[\"validation\"]])\n",
        "\n",
        "trainer_1 = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_val_dataset,  \n",
        "    eval_dataset=processed_dataset[\"test\"],  \n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics_tune,\n",
        "    tokenizer=tokenizer,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "7d9d14419adb4c2490d66dacd014742f"
          ]
        },
        "id": "8mfYzEv8zNBK",
        "outputId": "aba5866b-69ae-4f0d-cd51-31846f406405"
      },
      "outputs": [],
      "source": [
        "predictions, labels, _ = trainer_1.predict(processed_dataset[\"test\"])\n",
        "predicted_indices = np.argmax(predictions, axis=-1)\n",
        "true_labels,true_predictions = get_preds_and_labels((predictions, labels))\n",
        "all_metrics=metric.compute(predictions=true_predictions, references=true_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfNsf2uMzNBK",
        "outputId": "6a63a7b3-4146-4c61-e185-88f16d1ca53d"
      },
      "outputs": [],
      "source": [
        "all_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEbzXwTJzNBL",
        "outputId": "2bf95057-be94-4664-b6fc-c266159fab9e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "flat_true_labels = [label for sublist in true_labels for label in sublist]\n",
        "flat_true_predictions = [pred for sublist in true_predictions for pred in sublist]\n",
        "\n",
        "label_names = ['O', 'B-Drug', 'I-Drug', 'B-ADR', 'I-ADR', 'B-Disease', 'I-Disease', 'B-Symptom', 'I-Symptom', 'B-Finding', 'I-Finding']\n",
        "\n",
        "cm = confusion_matrix(flat_true_labels, flat_true_predictions, labels=label_names)\n",
        "\n",
        "short_labels = [label for label in label_names]\n",
        "df_cm = pd.DataFrame(cm, index=short_labels, columns=short_labels)\n",
        "\n",
        "df_cm_percentage = (df_cm / df_cm.sum().sum() * 100).round(3)\n",
        "\n",
        "\n",
        "pd.set_option('display.expand_frame_repr', False)\n",
        "df_cm_percentage_str = df_cm_percentage.to_string().replace('.000', '    ')\n",
        "\n",
        "print(df_cm_percentage_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTsRbkcRzNBL",
        "outputId": "6737a240-e30e-4592-a4a1-855913b31bff"
      },
      "outputs": [],
      "source": [
        "df_cm_percentage_latex = df_cm_percentage.to_latex(float_format=\"%.3f\")\n",
        "\n",
        "print(df_cm_percentage_latex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0IfsCEvzNBL",
        "outputId": "200a1674-f738-4a37-af8d-9ef60b9ad980"
      },
      "outputs": [],
      "source": [
        "print(df_cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhQD30RBzNBS",
        "outputId": "84c81bf6-cd9c-4729-cbbf-901c2aa6ef10"
      },
      "outputs": [],
      "source": [
        "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "y_true = true_labels\n",
        "y_pred = true_predictions\n",
        "\n",
        "print(\"Precision: \", precision_score(y_true, y_pred))\n",
        "print(\"Recall: \", recall_score(y_true, y_pred))\n",
        "print(\"F1-Score: \", f1_score(y_true, y_pred))\n",
        "print(\"\\nClassification Report: \")\n",
        "print(classification_report(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGmgvBQqzNBS",
        "outputId": "e420db48-24b5-436f-bff7-7ce2e940b92b"
      },
      "outputs": [],
      "source": [
        "label_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUCUOzH1zNBT"
      },
      "source": [
        "# Albert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjylSkZu4dtV"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3zU9FzKzNBT"
      },
      "outputs": [],
      "source": [
        "model_checkpoint = \"albert-base-v2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHV9RId5zNBT",
        "outputId": "95233dc3-484a-4710-b57c-da38527f2fb4"
      },
      "outputs": [],
      "source": [
        "i=145\n",
        "print(dataset[i]['file_names'])\n",
        "tokens = dataset[i]['tokens']\n",
        "tags = dataset[i]['labels']\n",
        "\n",
        "for token, tag in zip(tokens, tags):\n",
        "    if tag != -100:\n",
        "        tag = label_names[tag]\n",
        "    print(f\"Token: {token}, Tag: {tag}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHIp0ab-zNBT",
        "outputId": "50288aff-74fa-4147-851a-2b6acc409995"
      },
      "outputs": [],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpGkWBSJzNBU",
        "outputId": "f6584bb8-d949-479f-fb3c-b8aae4486d0d"
      },
      "outputs": [],
      "source": [
        "processed_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-mV0MaWzNBU",
        "outputId": "4cb5c40c-cd6c-433a-8ebc-a566a8fab2ee"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForTokenClassification\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsOD2ITZ4Eve"
      },
      "source": [
        "## Hyper-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8wJMT1P4S-G"
      },
      "source": [
        "### Baseline Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tw_-R3Y1zNBU"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"albert\", \n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    push_to_hub=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "7e42435597f84256a74845f9e6bb20fe",
            "b81ccb26b36e4b628c5428468630d75b",
            "24bc7b129ce64657820f6b9a9c4722ad",
            "cf0b6579f6d3434aae37461a55b72aac"
          ]
        },
        "id": "DzMhugcLzNBU",
        "outputId": "78efbb8a-e528-495d-a918-c523133c2b70"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=processed_dataset[\"train\"],\n",
        "    eval_dataset=processed_dataset[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjsR6JzKzNBW"
      },
      "source": [
        "### Other Combinations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Quoq-3szNBW",
        "outputId": "afca9056-c889-4abb-a9b4-9b1c015b2e43"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "trainer_tuner = Trainer(\n",
        "    model=None,\n",
        "    args=args_tuner,\n",
        "    train_dataset=processed_dataset[\"train\"],\n",
        "    eval_dataset=processed_dataset[\"validation\"],\n",
        "    compute_metrics=compute_metrics_tune,\n",
        "    tokenizer=tokenizer,\n",
        "    model_init=model_init,\n",
        "    data_collator=data_collator,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "2cf68efbaa9d4158a617d6d0c43dfd17",
            "7cba2f915184421b83ba4ffe2c47e36d",
            "4b68164002544a17b401196d8a96f772",
            "d3335f23e31b499c87d8511514b64b71",
            "92323b10f0c34d0c94d37bc85249ed1f",
            "28f735c42d2244cc96444eaa4a7aca76",
            "70a2e5525a26496c9fdeca830be4a82d",
            "3ae3f3a8236c4fd08980ad4998415c06",
            "c9cbb97b63024ad1802b4e1bdb392658",
            "f261fa5d45924a2890b5b67d2b3e1222",
            "72700ccbf0f547858e6d870c8b357fd8",
            "d74b9ca23d414155ba78b9b6eac73a6b",
            "785600c747e447e781b55419f2a97788",
            "ae794ddf2a1b407884b2f5216faafd6f",
            "db08a03815344187a6ecc74d55b21e0b",
            "5e43157591a045c5b5125d62894ca50a",
            "3925e28eeee3451c80c81876f0074644",
            "9ce3c69e43454a5a83067abbed2cc343",
            "682db68889464955b6dad0af06b25913",
            "26979a8ff5f246a7be89699914aa5dbf",
            "e1858c1492f64ff6b1ec26f9b831cbc1",
            "947aee24dcde4c51ac2bf5f65d2d8273",
            "9f4ef0d029d74bddbdfb008222cb4430",
            "d803617e24fc4f709e4e2c3b1a632912",
            "a74c0224f0cc443ea94606eecacc9f44",
            "5252c6f272db4b498013c5c791709b1f",
            "d6a3ca2ed7324bc0a1226d882b52b498",
            "e9943e134fbd4846bc4e95bc916299a4",
            "42ab562072a0411db160318bea935a6f",
            "3f16d264dde4417aa9fdd784dfb5804e",
            "defb36208716477488548e1e852e8411",
            "6b9fa9d8aeb843c5ad64a2f2d3f433dd",
            "fa19e90fbf9d434fae18f96f14ea1169",
            "9211655128364368a3a33416db09ca9b",
            "5d4266a0115241cbaa44c891f789780c",
            "e0a68bc70b4142f0a0f3f82282aed9b7",
            "1ea15a3811754201b1f7a29a4aeb9729",
            "b3dbf65c8587417c898947ab4230d2e9",
            "8996cd51549f421eb7dd7543fae57ab2",
            "620f0f5600744b4ba8d6738f60e3cffb"
          ]
        },
        "id": "x_IiDbdGzNBW",
        "outputId": "2bd296b3-b7b4-4856-ce1b-f14cac597ea7"
      },
      "outputs": [],
      "source": [
        "best_trial = trainer_tuner.hyperparameter_search(\n",
        "    direction=\"maximize\",\n",
        "    backend=\"optuna\",\n",
        "    hp_space=optuna_hp_space,\n",
        "    n_trials=20\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCsBkXKNzNBW"
      },
      "source": [
        "#### Model 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTM1-HfJzNBW"
      },
      "outputs": [],
      "source": [
        "# [I 2024-01-03 11:24:10,550]\n",
        "# Trial 10 finished with value: 2.066261419601351 and parameters: {'learning_rate': 9.55234940591104e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.08938621127315785, 'warmup_steps': 223, 'gradient_accumulation_steps': 1}. Best is trial 10 with value: 2.066261419601351.\n",
        "# Some weights of AlbertForTokenClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
        "# You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
        "# {'eval_loss': 0.39240533113479614, 'eval_precision': 0.5277108433734939, 'eval_recall': 0.292, 'eval_f1': 0.37596566523605146, 'eval_accuracy': 0.8705849109918056, 'eval_runtime': 2.3539, 'eval_samples_per_second': 258.3, 'eval_steps_per_second': 4.248, 'epoch': 0.3}\n",
        "# {'train_runtime': 12.1387, 'train_samples_per_second': 135.163, 'train_steps_per_second': 8.485, 'train_loss': 0.7450381980358975, 'epoch': 0.3}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzckT20TzNBW",
        "outputId": "690d71ed-e0b2-477c-8280-9f704c633966"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAJVqvJ_zNBX"
      },
      "outputs": [],
      "source": [
        "args_test = []\n",
        "args_test.append(TrainingArguments(\n",
        "    output_dir = \"./albert_test\",\n",
        "    optim=\"adamw_torch\",\n",
        "    per_device_train_batch_size=16,  \n",
        "    learning_rate=9.55234940591104e-05,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.08938621127315785,\n",
        "    warmup_steps=223,\n",
        "    gradient_accumulation_steps=1,\n",
        "    push_to_hub=False,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "0789853884204ae090f8aaa0d3a6c32f",
            "375c387c31004d3bac21bf85b1359f6a",
            "3060253bcdc84236b1053633dbc79d62",
            "61da5d7fea124dbb8a0b935362f43e30"
          ]
        },
        "id": "gGqhk8rBzNBX",
        "outputId": "19b138de-31d1-402d-d1b3-830104f8fec2"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "trainer_test = []\n",
        "trainer_test.append(Trainer(\n",
        "    model=model,\n",
        "    args=args_test[0],\n",
        "    train_dataset=processed_dataset[\"train\"],\n",
        "    eval_dataset=processed_dataset[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics_tune,\n",
        "    tokenizer=tokenizer,\n",
        "))\n",
        "trainer_test[0].train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsc38FZZzNBX"
      },
      "source": [
        "#### Model 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydkH_yV6zNBX"
      },
      "outputs": [],
      "source": [
        "# [I 2024-01-03 11:27:29,424] Trial 17 finished with value: 2.3091917346772814 and parameters: {'learning_rate': 5.643324435863421e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.09606971752344114, 'warmup_steps': 183, 'gradient_accumulation_steps': 2}. Best is trial 17 with value: 2.3091917346772814.\n",
        "# Some weights of AlbertForTokenClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
        "# You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
        "# {'eval_loss': 0.3853124678134918, 'eval_precision': 0.42016806722689076, 'eval_recall': 0.5333333333333333, 'eval_f1': 0.47003525264394835, 'eval_accuracy': 0.8856550814731091, 'eval_runtime': 2.3471, 'eval_samples_per_second': 259.041, 'eval_steps_per_second': 4.261, 'epoch': 0.3}\n",
        "# {'train_runtime': 11.9747, 'train_samples_per_second': 137.014, 'train_steps_per_second': 4.343, 'train_loss': 1.2237023264169693, 'epoch': 0.3}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOTfW14tzNBX"
      },
      "outputs": [],
      "source": [
        "args_test = []\n",
        "args_test.append(TrainingArguments(\n",
        "    output_dir = \"./albert_test\",\n",
        "    optim=\"adamw_torch\",\n",
        "    per_device_train_batch_size=16, \n",
        "    learning_rate=5.643324435863421e-05,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.09606971752344114,\n",
        "    warmup_steps=183,\n",
        "    gradient_accumulation_steps=2,\n",
        "    push_to_hub=False,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "75f1ce5843254106bb71349a72ab8531",
            "dc3382b7c0fa4ff2a4346659ae19df21",
            "af35bcfe07e2449c85e5e17b7ca87774",
            "89bd6cc510af47098f5fb8e20db51847"
          ]
        },
        "id": "NINXQyDzzNBY",
        "outputId": "51cf1b51-bb98-491c-9a29-1d57963d280d"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "trainer_test = []\n",
        "trainer_test.append(Trainer(\n",
        "    model=model,\n",
        "    args=args_test[0],\n",
        "    train_dataset=processed_dataset[\"train\"],\n",
        "    eval_dataset=processed_dataset[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics_tune,\n",
        "    tokenizer=tokenizer,\n",
        "))\n",
        "trainer_test[0].train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RH8NH6jrzNBY"
      },
      "source": [
        "#### Model 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Pw2b94EzNBY"
      },
      "outputs": [],
      "source": [
        "# [I 2024-01-03 11:29:46,281] Trial 19 finished with value: 2.26373217447632 and parameters: {'learning_rate': 3.527893281297765e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.03473836154590933, 'warmup_steps': 458, 'gradient_accumulation_steps': 1}. Best is trial 17 with value: 2.3091917346772814.\n",
        "# {'eval_loss': 0.37651291489601135, 'eval_precision': 0.4409937888198758, 'eval_recall': 0.47333333333333333, 'eval_f1': 0.4565916398713826, 'eval_accuracy': 0.8928134124517284, 'eval_runtime': 2.34, 'eval_samples_per_second': 259.825, 'eval_steps_per_second': 4.273, 'epoch': 0.3}\n",
        "# {'train_runtime': 12.0941, 'train_samples_per_second': 135.661, 'train_steps_per_second': 8.517, 'train_loss': 1.201701590158407, 'epoch': 0.3}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9WLFdRhzNBY"
      },
      "outputs": [],
      "source": [
        "args_test = []\n",
        "args_test.append(TrainingArguments(\n",
        "    output_dir = \"./albert_test\",\n",
        "    optim=\"adamw_torch\",\n",
        "    per_device_train_batch_size=16, \n",
        "    learning_rate=3.527893281297765e-05,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.03473836154590933,\n",
        "    warmup_steps=458,\n",
        "    gradient_accumulation_steps=1,\n",
        "    push_to_hub=False,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "1f4ae0ec97464ad9b4193e96e001b008",
            "1453bd4473e44e769f1df6283746d123",
            "92ecf935f9b446eba69ac2f028f494a9",
            "7ca0363f78624873bf59d6f285d6e820"
          ]
        },
        "id": "2GgshSbHzNBY",
        "outputId": "3ae8a83a-153a-4bb8-9cbe-3f233ee7a2f0"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "trainer_test = []\n",
        "trainer_test.append(Trainer(\n",
        "    model=model,\n",
        "    args=args_test[0],\n",
        "    train_dataset=processed_dataset[\"train\"],\n",
        "    eval_dataset=processed_dataset[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics_tune,\n",
        "    tokenizer=tokenizer,\n",
        "))\n",
        "trainer_test[0].train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIij4rr64ood"
      },
      "source": [
        "## Complete Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "75fd85a32710418faef0902b6d532c2b",
            "8f418fc404b84942b258c659660812a2",
            "3665f60d7ac5421ca53a3f717d59e3c8"
          ]
        },
        "id": "6mMdnGf7zNBU",
        "outputId": "9f82f95f-8585-41fc-f5bb-94d9ca864866"
      },
      "outputs": [],
      "source": [
        "from datasets import concatenate_datasets\n",
        "\n",
        "train_val_dataset = concatenate_datasets([processed_dataset[\"train\"], processed_dataset[\"validation\"]])\n",
        "\n",
        "trainer_1 = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_val_dataset,\n",
        "    eval_dataset=processed_dataset[\"test\"], \n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics_tune,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "trainer_1.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-sUMMyP4xa-"
      },
      "source": [
        "### Reports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "eacaa1a19709404aab0804bd61922b27"
          ]
        },
        "id": "Epou59phzNBV",
        "outputId": "b33244a7-634c-43af-deb0-b6accc80b03b"
      },
      "outputs": [],
      "source": [
        "predictions, labels, _ = trainer_1.predict(processed_dataset[\"test\"])\n",
        "predicted_indices = np.argmax(predictions, axis=-1)\n",
        "true_labels,true_predictions = get_preds_and_labels((predictions, labels))\n",
        "all_metrics=metric.compute(predictions=true_predictions, references=true_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WmgJ3LnzNBV",
        "outputId": "4fab84cb-b94e-43f8-8f62-3ab91189c88c"
      },
      "outputs": [],
      "source": [
        "all_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JExuEFEczNBV",
        "outputId": "5c16a906-961e-4b00-e948-8e72ac2a7af6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "flat_true_labels = [label for sublist in true_labels for label in sublist]\n",
        "flat_true_predictions = [pred for sublist in true_predictions for pred in sublist]\n",
        "\n",
        "cm = confusion_matrix(flat_true_labels, flat_true_predictions, labels=label_names)\n",
        "short_labels = [label for label in label_names]\n",
        "\n",
        "df_cm = pd.DataFrame(cm, index=short_labels, columns=short_labels)\n",
        "df_cm_percentage = (df_cm / df_cm.sum().sum() * 100).round(3)\n",
        "pd.set_option('display.expand_frame_repr', False)\n",
        "df_cm_percentage_str = df_cm_percentage.to_string().replace('.000', '    ')\n",
        "\n",
        "print(df_cm_percentage_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IEwo6_izNBV",
        "outputId": "084462bb-702e-42b6-c9e5-099c4e3cfd05"
      },
      "outputs": [],
      "source": [
        "df_cm_percentage_latex = df_cm_percentage.to_latex(float_format=\"%.3f\")\n",
        "\n",
        "print(df_cm_percentage_latex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znX-Pgi3zNBV",
        "outputId": "7a26a4d0-6311-4bdb-c3fb-0ff86a537f0e"
      },
      "outputs": [],
      "source": [
        "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "y_true = true_labels\n",
        "y_pred = true_predictions\n",
        "\n",
        "print(\"Precision: \", precision_score(y_true, y_pred))\n",
        "print(\"Recall: \", recall_score(y_true, y_pred))\n",
        "print(\"F1-Score: \", f1_score(y_true, y_pred))\n",
        "print(\"\\nClassification Report: \")\n",
        "print(classification_report(y_true, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "PdMuL-KJzNAw",
        "8ByvXxZkzNA7",
        "fz6E_eSKzNA8",
        "aC4qM9ZT25De",
        "zTgIlhHF3MM-",
        "RHz6hpXkzNA_",
        "f4o35PRCzNBJ",
        "oCsBkXKNzNBW",
        "hsc38FZZzNBX",
        "RH8NH6jrzNBY"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python nlp",
      "language": "python",
      "name": "nlp"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
